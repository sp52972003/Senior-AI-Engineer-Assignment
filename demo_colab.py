# -*- coding: utf-8 -*-
"""Senior AI Engineer Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qe29eHj-dpqz3gBjy84NK9ldQlx58uz
"""

!pip install google-play-scraper sentence-transformers pandas numpy scikit-learn tqdm

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from google_play_scraper import reviews
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from tqdm import tqdm

from google_play_scraper import reviews
from datetime import datetime, timedelta
import pandas as pd

def fetch_reviews(app_id, days=30):
    all_reviews = []
    cutoff_date = datetime.now() - timedelta(days=days)

    result, _ = reviews(
        app_id,
        lang="en",
        country="in",
        count=1000
    )

    for r in result:
        if r["at"] >= cutoff_date:
            all_reviews.append({
                "date": r["at"].date(),
                "content": r["content"]
            })

    return pd.DataFrame(all_reviews)

df_reviews = fetch_reviews("com.application.zomato")
df_reviews.head()

daily_batches = {
    date: group["content"].tolist()
    for date, group in df_reviews.groupby("date")
}

print("Total days with data:", len(daily_batches))

from sentence_transformers import SentenceTransformer

model = SentenceTransformer("all-MiniLM-L6-v2")

def extract_topics(reviews):
    topics = []

    issue_keywords = [
        "delivery", "late", "delay", "rude", "refund", "cancel",
        "cold", "stale", "missing", "wrong", "map", "bad"
    ]

    positive_keywords = [
        "good", "great", "excellent", "awesome", "wow", "nice", "amazing"
    ]

    for text in reviews:
        text_l = text.lower()

        if any(k in text_l for k in issue_keywords):
            topics.append(text_l)

        elif any(k in text_l for k in positive_keywords):
            topics.append("positive feedback")

    return topics

from sklearn.metrics.pairwise import cosine_similarity

def deduplicate_topics(topic_texts, threshold=0.75):
    if not topic_texts:
        return []

    if len(set(topic_texts)) == 1:
        return list(set(topic_texts))

    embeddings = model.encode(topic_texts)
    used = set()
    final_topics = []

    for i, emb in enumerate(embeddings):
        if i in used:
            continue

        sims = cosine_similarity([emb], embeddings)[0]
        group_idx = [j for j, s in enumerate(sims) if s > threshold]

        used.update(group_idx)
        final_topics.append(topic_texts[i])

    return final_topics

from tqdm import tqdm

def build_trend_table(daily_batches):
    trend = {}

    for date, reviews in tqdm(daily_batches.items()):
        extracted = extract_topics(reviews)
        deduped = deduplicate_topics(extracted)

        for topic in deduped:
            if topic not in trend:
                trend[topic] = {}
            trend[topic][date] = trend[topic].get(date, 0) + 1

    return trend

trend_data = build_trend_table(daily_batches)

from datetime import timedelta

end_date = max(daily_batches.keys())
dates = [end_date - timedelta(days=i) for i in range(29, -1, -1)]

rows = []
for topic, counts in trend_data.items():
    row = {"Topic": topic}
    for d in dates:
        row[str(d)] = counts.get(d, 0)
    rows.append(row)

trend_df = pd.DataFrame(rows)
trend_df

trend_df.to_csv("trend_report.csv", index=False)
print("trend_report.csv saved")

from google.colab import files
files.download("trend_report.csv")

